{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loaded mnist data!\n",
      "training_data (60000, 1, 28, 28)\n",
      "training_labels (60000,)\n",
      "test_data (10000, 1, 28, 28)\n",
      "\n",
      "loaded spam data!\n",
      "training_data (4171, 32)\n",
      "training_labels (4171,)\n",
      "test_data (1000, 32)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal, norm\n",
    "from scipy.linalg import  solve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tqdm import  tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import sys\n",
    "if sys.version_info[0] < 3:\n",
    "\traise Exception(\"Python 3 not detected.\")\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import io\n",
    "os.chdir('data')\n",
    "fields = \"training_data\", \"training_labels\", \"test_data\"\n",
    "data ={}\n",
    "if __name__ == \"__main__\":\n",
    "    for data_name in [\"mnist\", \"spam\"]:\n",
    "        data[data_name] = np.load(f\"{data_name}-data-hw3.npz\")\n",
    "        print(\"\\nloaded %s data!\" % data_name)\n",
    "        for field in fields:\n",
    "            print(field, data[data_name][field].shape)\n",
    "os.chdir('..')\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting...: 10it [00:18,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.92965\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      5923\n",
      "           1       0.97      0.96      0.96      6742\n",
      "           2       0.94      0.94      0.94      5993\n",
      "           3       0.93      0.92      0.92      6162\n",
      "           4       0.97      0.91      0.94      5862\n",
      "           5       0.97      0.86      0.91      5428\n",
      "           6       0.97      0.96      0.97      5870\n",
      "           7       0.96      0.88      0.92      6213\n",
      "           8       0.81      0.93      0.86      5851\n",
      "           9       0.84      0.95      0.89      5956\n",
      "\n",
      "    accuracy                           0.93     60000\n",
      "   macro avg       0.93      0.93      0.93     60000\n",
      "weighted avg       0.93      0.93      0.93     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train = data[\"mnist\"][\"training_data\"]\n",
    "labels = data[\"mnist\"][\"training_labels\"]\n",
    "train = train.reshape(train.shape[0], -1)  \n",
    "\n",
    "normalize = lambda x: x / (np.linalg.norm(x, ord=2, axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "#basically a baysian inference model\n",
    "class GaussClassifier:\n",
    "    def __init__(self):\n",
    "        self.mus = {}\n",
    "        self.covs = {}\n",
    "        self.priors = {}\n",
    "        self.classes = None\n",
    "        self.epsilon = 1e-5\n",
    "        self.cov_calc = {}\n",
    "    def normalize(self, x):\n",
    "        norm = np.linalg.norm(x, ord=2, axis=1, keepdims=True)  # Compute L2 norm\n",
    "        norm = np.where(norm == 0, self.epsilon, norm)  # Replace zeros with small value\n",
    "        return x / norm\n",
    "    def fit(self, X, Y, post=True):\n",
    "        self.post = post\n",
    "        X = self.normalize(X)\n",
    "        self.classes = np.unique(Y).tolist()\n",
    "        for c in self.classes:\n",
    "            x_c = X[Y == c]\n",
    "            mu = np.mean(x_c, axis=0)\n",
    "            cov = np.cov(x_c, bias=False, rowvar=False)\n",
    "            self.cov_calc[c] = cov\n",
    "            prior = len(x_c) / Y.shape[0]\n",
    "            self.mus[c] = mu\n",
    "            self.covs[c] = cov + self.epsilon * np.eye(cov.shape[0])  # Regularization\n",
    "            self.priors[c] = prior \n",
    "    def probability(self, X):\n",
    "        X_cpu =X\n",
    "        mus_cpu = np.stack([self.mus[c] for c in self.classes])\n",
    "        covs_cpu = {c: self.covs[c] for c in self.classes}\n",
    "        priors_cpu = np.array([self.priors[c] for c in self.classes])\n",
    "        log_probs = np.zeros((X_cpu.shape[0], len(self.classes))) \n",
    "\n",
    "        for idx, c in tqdm(enumerate(self.classes), desc=\"Predicting...\"):\n",
    "            log_probs[:, idx] = multivariate_normal.logpdf(X_cpu, mean=mus_cpu[idx], cov=covs_cpu[c])\n",
    "            if self.post:\n",
    "                log_probs[:,idx] += np.log(priors_cpu[idx])\n",
    "        return np.array(self.classes)[np.argmax(np.array(log_probs), axis=1)]\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = self.normalize(X)\n",
    "        return self.probability(X)\n",
    "\n",
    "model = GaussClassifier()\n",
    "model.fit(train, labels, False)\n",
    "preds = model.predict(train)\n",
    "accuracy = np.mean(preds == labels)\n",
    "print(f\"Train Accuracy: {accuracy}\")\n",
    "print(classification_report(labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  7.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8734166666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94      1109\n",
      "           1       0.92      0.95      0.94      1339\n",
      "           2       0.90      0.83      0.86      1254\n",
      "           3       0.83      0.85      0.84      1183\n",
      "           4       0.86      0.90      0.88      1174\n",
      "           5       0.85      0.81      0.83      1107\n",
      "           6       0.93      0.92      0.92      1183\n",
      "           7       0.93      0.85      0.88      1258\n",
      "           8       0.79      0.81      0.80      1177\n",
      "           9       0.81      0.87      0.84      1216\n",
      "\n",
      "    accuracy                           0.87     12000\n",
      "   macro avg       0.87      0.87      0.87     12000\n",
      "weighted avg       0.87      0.87      0.87     12000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class LDAClassifier(GaussClassifier):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        super().fit(X, Y) \n",
    "        X = self.normalize(X)\n",
    "        N = len(X)\n",
    "        k = len(self.classes)\n",
    "        self.cov_sum = np.zeros((X.shape[1], X.shape[1]))\n",
    "\n",
    "        # Compute the pooled covariance matrix\n",
    "        for c in self.classes:\n",
    "            X_c = X[Y == c]\n",
    "            self.cov_sum += len(X_c) * self.covs[c]  # Weighting by class size\n",
    "\n",
    "        self.cov_sum /= (N - k)  # Normalize pooled covariance\n",
    "        self.cov_sum_inv = solve(self.cov_sum, np.eye(self.cov_sum.shape[0]), assume_a='sym')  # More stable than np.linalg.inv()\n",
    "    def probability(self, X):\n",
    "\n",
    "        scores = np.zeros((X.shape[0], len(self.mus)))\n",
    "        for idx, c in tqdm(enumerate(self.mus.keys()), total=len(self.mus)):\n",
    "            mu_c = self.mus[c]\n",
    "            term1 = X @ self.cov_sum_inv @ mu_c  # x^T Sigma^{-1} mu_C\n",
    "            term2 = 0.5 * mu_c.T @ self.cov_sum_inv @ mu_c  # (1/2) mu_C^T Sigma^{-1} mu_C\n",
    "            term3 = np.log(self.priors[c])  # ln(prior)\n",
    "            scores[:, idx] = term1 - term2 + term3\n",
    "        return np.argmax(scores, axis=1) \n",
    "    def predict(self, X):\n",
    "        X = self.normalize(X)\n",
    "        return self.probability(X)\n",
    "        \n",
    "\n",
    "model = LDAClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "accuracy = np.mean(preds == y_test)\n",
    "print(f\"Train Accuracy: {accuracy}\")\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating probablities: 10it [00:13,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurcay: 0.9061666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97      1109\n",
      "           1       0.97      0.95      0.96      1339\n",
      "           2       0.91      0.93      0.92      1254\n",
      "           3       0.88      0.89      0.88      1183\n",
      "           4       0.94      0.90      0.92      1174\n",
      "           5       0.96      0.79      0.86      1107\n",
      "           6       0.97      0.94      0.96      1183\n",
      "           7       0.95      0.87      0.91      1258\n",
      "           8       0.74      0.90      0.81      1177\n",
      "           9       0.83      0.93      0.88      1216\n",
      "\n",
      "    accuracy                           0.91     12000\n",
      "   macro avg       0.91      0.91      0.91     12000\n",
      "weighted avg       0.91      0.91      0.91     12000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class QDAClassifier(GaussClassifier):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "\n",
    "    def fit(self,X,Y):\n",
    "        super().fit(X,Y,True)\n",
    "        X = self.normalize(X)\n",
    "        self.covs_inv = {}\n",
    "        for c in self.classes:\n",
    "            self.covs_inv[c] = solve(self.covs[c], np.eye(self.covs[c].shape[0]), assume_a='sym')  # More stable than np.linalg.inv()\n",
    "\n",
    "    def probability(self, X):\n",
    "        scores = np.zeros((X.shape[0], len(self.mus)))\n",
    "        for idx, c in tqdm(enumerate(self.classes), desc=\"Calculating probablities\"):\n",
    "            mean_c = self.mus[c]\n",
    "            cov_c = self.covs[c]\n",
    "\n",
    "            sign, logdet = np.linalg.slogdet(cov_c)  # Compute log determinant\n",
    "            inv_cov = np.linalg.inv(cov_c)  # Compute inverse\n",
    "            # Compute quadratic discriminant function\n",
    "            for i, x in enumerate(X):\n",
    "                diff = x - mean_c\n",
    "                term1 = -0.5 * np.dot(diff.T, np.dot(inv_cov, diff))  # (x - mu_C)^T Σ_C^{-1} (x - mu_C)\n",
    "                term2 = -0.5 * logdet  # -0.5 * log(|Σ_C|)\n",
    "                term3 = np.log(self.priors[c])  # log(P(y = C))\n",
    "                scores[i, idx] = term1 + term2 + term3 \n",
    "\n",
    "        return np.argmax(scores, axis=1)  # Assign to the class with highest score\n",
    "    def predict(self, X):\n",
    "        X = self.normalize(X)\n",
    "        return self.probability(X)  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "model = QDAClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "accuracy = np.mean(preds == y_test)\n",
    "print(f\"Accurcay: {accuracy}\")\n",
    "print(classification_report(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 333.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.LDAClassifier'> validation accuracy: 0.8802395209580839\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.92       569\n",
      "           1       0.90      0.70      0.79       266\n",
      "\n",
      "    accuracy                           0.88       835\n",
      "   macro avg       0.89      0.83      0.85       835\n",
      "weighted avg       0.88      0.88      0.88       835\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<__main__.LDAClassifier at 0x273ddf20e50>, 0.8802395209580839)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_model(model,train, labels):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train, labels, test_size=0.2, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    acc = np.mean(preds == y_test)\n",
    "    print(f\"{type(model)} validation accuracy: {acc}\")\n",
    "    print(classification_report(y_test, preds))\n",
    "    return model, acc\n",
    "os.chdir(\"data\")\n",
    "dta = np.load(\"spam-data.npz\")\n",
    "os.chdir(\"..\")\n",
    "train = dta[\"training_data\"]\n",
    "labels = dta[\"training_labels\"]\n",
    "test = dta[\"test_data\"]\n",
    "evaluate_model(LDAClassifier(), train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
